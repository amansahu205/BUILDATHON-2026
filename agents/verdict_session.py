import os
import json
import signal
import sys
import argparse
from pathlib import Path

from elevenlabs.client import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation
from elevenlabs.conversational_ai.default_audio_interface import DefaultAudioInterface

AGENT_ID = os.getenv("AGENT_ID", "agent_5201khzcc407fhntbvdsabc0txr5")
API_KEY = os.getenv("ELEVENLABS_API_KEY")

CASES_PATH = Path(__file__).parent.parent / "data" / "verdict_cases.json"


def load_cases(path: Path = CASES_PATH) -> list[dict]:
    with open(path) as f:
        return json.load(f)


def get_case(cases: list[dict], case_id: str) -> dict:
    for c in cases:
        if c["id"] == case_id:
            return c
    available = [c["id"] for c in cases]
    print(f"Case '{case_id}' not found. Available cases:")
    for cid in available:
        print(f"  - {cid}")
    sys.exit(1)


def build_system_prompt(case: dict) -> str:
    return f"""You are an elite Litigation Consultant and Behavioral Analyst. Your objective is to analyze a tagged mock deposition transcript between an opposing counsel [Interrogator] and your client [Witness] and generate a strictly formatted JSON report.
The input transcript includes behavioral audio tags (e.g., [pause], [sigh], [nervous laugh], [throat_clear]) generated by an upstream audio analysis pipeline. You must treat these tags as objective facts regarding the witness's vocal state.

INTERROGATOR CONTEXT:
The Interrogator was operating at a {case['aggression_level']} aggression level. Their primary tactics were deploying strategic silence, trapping the witness in contradictions, and confronting them with prior statements/exhibits.

CASE CONTEXT:
Case: {case['case_name']}
Case Type: {case['case_type']}
Opposing Party: {case['opposing_party']}
Deposition Date: {case['deposition_date']}
Witness: {case['witness_name']}
Witness Role: {case['witness_role']}
Focus Areas: {case['focus_areas']}
Exhibits in Evidence: {case['exhibit_list']}
Prior Statements to Challenge: {case['prior_statements']}
Key Facts: {case['extracted_facts']}

YOUR SCORING RUBRIC (Scale of 1 to 100):
Evaluate the witness on these 5 dimensions, paying special attention to how they handled the Interrogator's traps:

Composure (Calm under pressure)
High Score: Absorbs aggressive questioning and the "Confrontation Protocol" (exhibit drops) without vocal changes.
Penalties: Heavy use of [sigh], [nervous], defensiveness, or verbal agitation when confronted with a document.

Tactical Discipline (Handling Silence & Traps)
High Score: Gives short answers and remains completely silent when the Interrogator uses "strategic silence" to bait them.
Penalties: Over-explaining, filling dead air with rambling, volunteering unasked information.

Professionalism (Courtroom demeanor)
High Score: Respectful, neutral, objective, especially during Phase 1 (The Oath).
Penalties: Any occurrence of [laugh], [scoff], sarcasm, or arguing with the Interrogator.

Directness (Evasion tracking)
High Score: Concise answers ("Yes", "No", "I do not recall").
Penalties: Saying "I don't recall" more than twice on the same topic, dodging the core question, forcing the Interrogator to repeat themselves.

Consistency (Endurance over time)
High Score: Maintains the exact same narrative and tone, even when the Interrogator circles back to a topic 20 minutes later.
Penalties: Contradicting a prior statement within the session, suddenly increasing [pauses], or shifting tone on specific focus areas.

INSTRUCTIONS FOR ANALYSIS:
Scan the transcript specifically looking for the juxtaposition of the Interrogator's traps (silence, exhibits, looping questions) and the Witness's behavioral tags.
Identify the single most damaging exchange (the "Critical Vulnerability") where the witness fell into a legal trap or their metrics dropped the most.
Formulate a step-by-step rationale for each of the 5 dimensions before assigning a score.

OUTPUT FORMAT:
You must return ONLY a valid JSON object. Do not include markdown formatting, conversational filler, or introductory text. Use the exact keys provided below.
{{
  "analysis_rationale": {{
    "composure_reasoning": "Brief explanation of evidence found...",
    "tactical_discipline_reasoning": "...",
    "professionalism_reasoning": "...",
    "directness_reasoning": "...",
    "consistency_reasoning": "..."
  }},
  "spider_chart_scores": {{
    "composure": 0,
    "tactical_discipline": 0,
    "professionalism": 0,
    "directness": 0,
    "consistency": 0
  }},
  "critical_vulnerability": {{
    "interrogator_tactic_used": "What trap did the Interrogator set? (e.g., Strategic Silence, Exhibit Confrontation)",
    "witness_reaction": "How the witness physically/vocally reacted based on tags and transcript",
    "trial_risk": "How this specific failure will be used against them in court"
  }},
  "coaching_directive": "One actionable, imperative sentence telling the witness exactly how to counter this specific interrogator tactic."
}}"""


def list_cases(cases: list[dict]) -> None:
    print("\nAvailable VERDICT cases:\n")
    for c in cases:
        witness = c["witness_name"].split(";")[0].strip()
        print(f"  {c['id']:<25} {c['case_name']}")
        print(f"  {'':25} Witness: {witness} | Aggression: {c['aggression_level']}")
        print()


def run_session(case: dict, agent_id: str, api_key: str) -> None:
    client = ElevenLabs(api_key=api_key)

    conversation = Conversation(
        client,
        agent_id=agent_id,
        requires_auth=True,
        audio_interface=DefaultAudioInterface(),
        callback_agent_response=lambda r: print(f"\n  [SEAN CAHILL]: {r}"),
        callback_agent_response_correction=lambda orig, corrected: print(
            f"\n  [SEAN CAHILL] (corrected): {corrected}"
        ),
        callback_user_transcript=lambda t: print(f"\n  [WITNESS]: {t}"),
        callback_latency_measurement=lambda ms: print(f"    latency: {ms}ms"),
    )

    witness = case["witness_name"].split(";")[0].strip()
    print(f"\n{'=' * 60}")
    print(f"  VERDICT — Deposition Session")
    print(f"{'=' * 60}")
    print(f"  Case:        {case['case_name']}")
    print(f"  Witness:     {witness}")
    print(f"  Case Type:   {case['case_type']}")
    print(f"  Aggression:  {case['aggression_level']}")
    print(f"{'=' * 60}")
    print(f"  Speak into your microphone as the witness.")
    print(f"  Press Ctrl+C to end the session.\n")

    signal.signal(signal.SIGINT, lambda sig, frame: conversation.end_session())

    conversation.start_session(
        user_id=f"verdict_{case['id']}"
    )

    conversation_id = conversation.wait_for_session_end()
    print(f"\n{'=' * 60}")
    print(f"  Session complete. Conversation ID: {conversation_id}")
    print(f"  Review transcript: elevenlabs.io > Conversational AI > History")
    print(f"{'=' * 60}\n")


def main():
    parser = argparse.ArgumentParser(
        description="VERDICT — AI Deposition Interrogation System"
    )
    parser.add_argument(
        "case_id",
        nargs="?",
        default=None,
        help="Case ID to run (e.g. lyman_v_cctd). Omit to list available cases.",
    )
    parser.add_argument(
        "--list",
        action="store_true",
        help="List all available cases",
    )
    parser.add_argument(
        "--agent-id",
        default=AGENT_ID,
        help="ElevenLabs Agent ID (default: env AGENT_ID)",
    )
    parser.add_argument(
        "--api-key",
        default=API_KEY,
        help="ElevenLabs API key (default: env ELEVENLABS_API_KEY)",
    )
    args = parser.parse_args()

    cases = load_cases()

    if args.list or args.case_id is None:
        list_cases(cases)
        return

    if not args.api_key:
        print("Error: ELEVENLABS_API_KEY environment variable not set.")
        print("  export ELEVENLABS_API_KEY=your_key_here")
        sys.exit(1)

    case = get_case(cases, args.case_id)
    run_session(case, args.agent_id, args.api_key)


if __name__ == "__main__":
    main()
